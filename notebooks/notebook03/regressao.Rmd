---
title: "Modelos de Regressão Linear"
output: html_notebook
---

```{r setup, warning=FALSE, message=FALSE}
# pacotes necessarios para o lab
library(ISLR2)
```


## Modelo de Regressão Linear Simples

The `ISLR2` library contains the `Boston`  data set, which
records `medv` (median house value) for $506$ census tracts in Boston. We will seek to predict `medv` using $12$ predictors such as `rmvar` (average number of  rooms per house), `age` (average age of houses), and `lstat` (percent of households with low socioeconomic status).


```{r}
head(Boston)
```


To find out more about the data set, we can type `?Boston`.

We will start by using the `lm()` function to fit a simple  linear regression model, with `medv` as the response and `lstat`  as the predictor. The basic syntax is {\R{lm(y $\sim$ x, data)}}, where `y` is the response, `x` is the predictor, and `data` is the data set in which these two variables are kept.

```{r}
lm.fit <- lm(medv ~ lstat)
```


The command causes an error because `R` does not know where to find the variables `medv` and `lstat`. The next line tells `R` that the variables are in `Boston`. If we attach `Boston`, the first line works fine because `R` now recognizes the variables.

```{r}
lm.fit <- lm(medv ~ lstat, data = Boston)
attach(Boston)
lm.fit <- lm(medv ~ lstat)
```


If we type `lm.fit`,  some basic information about the model is output. For more detailed information, we use `summary(lm.fit)`. This gives us $p$-values and standard errors for the coefficients, as well as the $R^2$ statistic and $F$-statistic for the model.

```{r}
lm.fit
summary(lm.fit)
```

We can use the `names()` function in order to find out what other pieces of information  are stored in `lm.fit`.
Although we can extract these quantities by name---e.g. `lm.fit$coefficients`---it is safer to use the extractor functions like `coef()` to access them.

```{r}
names(lm.fit)
coef(lm.fit)
```


In order to obtain a confidence interval for the coefficient estimates, we can use the `confint()` command. Type `confint(lm.fit)` at the command line to obtain the confidence intervals.


```{r}
confint(lm.fit)
```


The `predict()` function can be used to produce confidence intervals and prediction intervals for the prediction of `medv` for a given value of `lstat`.

```{r}
predict(lm.fit, data.frame(lstat = (c(5, 10, 15))),
    interval = "confidence")
predict(lm.fit, data.frame(lstat = (c(5, 10, 15))),
    interval = "prediction")
```


For instance, the 95\,\% confidence interval associated with a `lstat` value of 10 is $(24.47, 25.63)$, and the 95\,\% prediction interval is $(12.828, 37.28)$.

As expected, the confidence and prediction intervals are centered around the same point (a predicted value of $25.05$ for `medv` when `lstat` equals 10), but the latter are substantially wider.

We will now plot `medv` and `lstat` along with the least squares regression line using the `plot()` and `abline()` functions.

```{r}
plot(lstat, medv)
abline(lm.fit)
```


There is some evidence for non-linearity in the relationship between `lstat` and `medv`. We will explore this issue  later in this lab.

The `abline()` function can be used to draw any line, not just the least squares regression line.

To draw a line with intercept `a` and slope `b`, we  type `abline(a, b)`. Below we experiment with some additional settings for plotting lines and points.

The `lwd = 3` command causes the width of the regression line to be increased by a factor of 3;  this works for the `plot()` and `lines()` functions also. We can also use the `pch` option to create different plotting symbols.


```{r}
plot(lstat, medv)
abline(lm.fit, lwd = 3)
abline(lm.fit, lwd = 3, col = "red")
plot(lstat, medv, col = "red")
plot(lstat, medv, pch = 20)
plot(lstat, medv, pch = "+")
plot(1:20, 1:20, pch = 1:20)
```

Next we examine some diagnostic plots, several of which were discussed
in Section 3.3.3. Four diagnostic plots are automatically
produced by applying the `plot()` function directly to the output
from `lm()`. 

In general, this command will produce one plot at a
time, and hitting *Enter* will generate the next plot. However,
it is often convenient to view all four plots together. We can achieve
this by using the `par()` and `mfrow()` functions, which tell `R` to split
the display screen into separate panels so that multiple plots can be
viewed simultaneously. For example,  `par(mfrow = c(2, 2))` divides the plotting region into a $2 \times 2$ grid of panels.

```{r}
par(mfrow = c(2, 2))
plot(lm.fit)
```


Alternatively, we can compute the residuals from a linear regression
fit using the `residuals()` function. The function
`rstudent()` will return the studentized residuals, and we
can use this function to plot the residuals against the fitted values.


```{r}
plot(predict(lm.fit), residuals(lm.fit))
plot(predict(lm.fit), rstudent(lm.fit))
```

On the basis of the residual plots, there is some evidence of non-linearity. Leverage statistics can be computed for any number of predictors using the `hatvalues()` function.

```{r}
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
```



## Modelo de Regressão Linear Múltipla

In order to fit a multiple linear regression model using least squares, we again use the `lm()` function. The syntax {\R{lm(y $\sim$ x1 + x2 + x3)}} is used to fit a model with three predictors, `x1`, `x2`, and `x3`.
The `summary()` function now outputs the regression coefficients for all the predictors.

```{r}
lm.fit <- lm(medv ~ lstat + age, data = Boston)
summary(lm.fit)
```

The `Boston` data set contains 12 variables, and so it would be cumbersome to have to type all of these in order to perform a regression using all of the predictors. Instead, we can use the following short-hand:

```{r}
lm.fit <- lm(medv ~ ., data = Boston)
summary(lm.fit)
```

We can access the individual components of a summary object by name
(type `?summary.lm` to see what is available). Hence
`summary(lm.fit)$r.sq` gives us the $R^2$, and
`summary(lm.fit)$sigma` gives us the RSE. 


The `vif()` function, part of the `car` package, can be used to 
compute variance inflation factors.   Most VIF's are
low to moderate for this data. The `car` package is not part of the 
base `R` installation so it must be downloaded the first time 
you use it via the `install.packages()` function in `R`.


```{r}
library(car)
vif(lm.fit)
```


Alternatively, the `update()` function can be used.

```{r}
lm.fit1 <- update(lm.fit, ~ . - age)
```



## Interações

It is easy to include interaction terms in a linear model using the `lm()` function. The syntax `lstat:black` tells `R` to include an interaction term between `lstat` and `black`.

The syntax `lstat * age` simultaneously includes `lstat`, `age`, and the interaction term `lstat`$\times$`age` as predictors; it is a shorthand for `lstat + age + lstat:age`. We can also pass in transformed versions of the predictors.

```{r}
summary(lm(medv ~ lstat * age, data = Boston))
```

  
  



## Transformações Não Lineares dos Preditores



## Preditores Qualitativos







